{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "\n",
        "# Load data\n",
        "mordred_df = pd.read_csv(\"Mordred_Descriptors.csv\", encoding=\"ISO-8859-1\")\n",
        "training_df = pd.read_csv(\"TASK1_training.csv\", encoding=\"ISO-8859-1\")\n",
        "stimulus_df = pd.read_csv(\"TASK1_Stimulus_definition.csv\", encoding=\"ISO-8859-1\")\n",
        "leaderboard_df = pd.read_csv(\"TASK1_leaderboard_set_Submission_form.csv\", encoding=\"ISO-8859-1\")\n",
        "test_df = pd.read_csv(\"TASK1_test_set_Submission_form.csv\", encoding=\"ISO-8859-1\")\n",
        "\n",
        "merged_features = pd.merge(stimulus_df, mordred_df, on=\"molecule\")\n",
        "train_full = pd.merge(training_df, merged_features, on=\"stimulus\")\n",
        "\n",
        "to_drop = [\n",
        "    \"stimulus\", \"molecule\", \"dilution\", \"solvent\", \"Intensity_label\",\n",
        "    \"Intensity\", \"Pleasantness\"\n",
        "]\n",
        "drop_cols = [col for col in to_drop if col in train_full.columns]\n",
        "train_features = train_full.drop(columns=drop_cols)\n",
        "\n",
        "# Drop non-numeric columns\n",
        "object_cols = train_features.select_dtypes(include='object').columns\n",
        "train_features = train_features.drop(columns=object_cols)\n",
        "\n",
        "# Extract targets\n",
        "target_cols = training_df.columns.tolist()[2:]  # descriptors start from column 3\n",
        "train_targets = train_full[target_cols]\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(train_features)\n",
        "X = pd.DataFrame(X_scaled, columns=train_features.columns)\n",
        "\n",
        "# Drop constant (zero-variance) columns\n",
        "X = X.loc[:, X.std() > 0]\n",
        "\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(0, inplace=True)  # Impute missing values safely\n",
        "\n",
        "\n",
        "\n",
        "# Align targets\n",
        "y = train_targets.loc[X.index]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_val)\n",
        "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "print(f\"Validation RMSE: {rmse:.4f}\")\n",
        "\n",
        "# ---- Prediction Function ----\n",
        "def prepare_and_predict(submission_df, features_df):\n",
        "    merged = pd.merge(submission_df, features_df, on=\"stimulus\")\n",
        "\n",
        "    # Drop any unwanted metadata or identifier columns\n",
        "    drop_candidates = [\n",
        "        \"stimulus\", \"CID_main\", \"dilution\", \"solvent\",\n",
        "        \"Intensity_label\", \"CID_mordred\", \"Dilution\", \"Solvent\", \"IntensityLevel\", \"molecule\"\n",
        "    ]\n",
        "    drop_cols = [col for col in drop_candidates if col in merged.columns]\n",
        "\n",
        "    # Drop object/string columns\n",
        "    X_submit = merged.drop(columns=drop_cols)\n",
        "    X_submit = X_submit.drop(columns=X_submit.select_dtypes(include='object').columns)\n",
        "\n",
        "    # Scale and align with training columns\n",
        "    X_submit_scaled = scaler.transform(X_submit)\n",
        "    X_submit_scaled = pd.DataFrame(X_submit_scaled, columns=X_submit.columns)\n",
        "    # Replace infs with NaNs\n",
        "    X_submit_scaled.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    # Fill NaNs with 0 (safe imputation) or drop them\n",
        "    X_submit_scaled.fillna(0, inplace=True)  # or use a trained imputer\n",
        "    X_submit_scaled = X_submit_scaled[X.columns]  # Keep only training-time columns\n",
        "\n",
        "    # Predict\n",
        "    y_submit_pred = model.predict(X_submit_scaled)\n",
        "\n",
        "    # Format output\n",
        "    result_df = pd.DataFrame(y_submit_pred, columns=train_targets.columns)\n",
        "    result_df.insert(0, \"stimulus\", submission_df[\"stimulus\"].values)\n",
        "    return result_df\n",
        "\n",
        "# ---- Predictions ----\n",
        "\n",
        "# Predict on leaderboard\n",
        "leaderboard_predictions = prepare_and_predict(leaderboard_df, merged_features)\n",
        "leaderboard_predictions.to_csv(\"TASK1_leaderboard_set_Submission_form.csv\", index=False)\n",
        "\n",
        "# Predict on test set\n",
        "test_predictions = prepare_and_predict(test_df, merged_features)\n",
        "test_predictions.to_csv(\"TASK1_Test_Predictions.csv\", index=False)\n",
        "\n",
        "print(\"Predictions saved to 'TASK1_leaderboard_set_Submission_form.csv' and 'TASK1_Test_Predictions.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwDKPPd1yqrq",
        "outputId": "139454bb-26f8-4c83-e390-78aadc39f77b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation RMSE: 0.0959\n",
            "Predictions saved to 'TASK1_Leaderboard_Predictions.csv' and 'TASK1_Test_Predictions.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "from scipy.stats import pearsonr\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def average_metrics(y_true, y_pred):\n",
        "    pearson_scores = []\n",
        "    cosine_distances = []\n",
        "    for i in range(y_true.shape[0]):\n",
        "        true_vec = y_true.iloc[i].values\n",
        "        pred_vec = y_pred[i]\n",
        "\n",
        "        # Pearson correlation\n",
        "        corr, _ = pearsonr(true_vec, pred_vec)\n",
        "        pearson_scores.append(corr)\n",
        "\n",
        "        # Cosine distance\n",
        "        cos_dist = cosine(true_vec, pred_vec)\n",
        "        cosine_distances.append(cos_dist)\n",
        "\n",
        "    avg_pearson = np.nanmean(pearson_scores)\n",
        "    avg_cosine_dist = np.nanmean(cosine_distances)\n",
        "\n",
        "    print(f\"Average Pearson Correlation: {avg_pearson:.4f}\")\n",
        "    print(f\"Average Cosine Distance: {avg_cosine_dist:.4f}\")\n",
        "    return avg_pearson, avg_cosine_dist\n",
        "\n",
        "y_val_pred=model.predict(X_val)\n",
        "average_metrics(y_val, y_val_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkmkvB-406CZ",
        "outputId": "c113faf1-9352-40fb-d585-61d7becee15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Pearson Correlation: 0.9951\n",
            "Average Cosine Distance: 0.0043\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(0.9951466272046495), np.float64(0.0043111152356154646))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average Pearson Correlation is close to 1 which means the model's predictions are very strongly correlated with the true perceptual profiles.\n",
        "\n",
        "Average Cosine Distance is close to 0. So the model's prediction profiles are closely aligned to the direction with the real descriptor profiles."
      ],
      "metadata": {
        "id": "ymqLB-EY9KME"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pcposgdE9prO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}